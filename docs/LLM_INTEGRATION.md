# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LM Studio –∏ Ollama

–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã –≤–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏—è VMS —Å LLM (Large Language Models) —á–µ—Ä–µ–∑ OpenAI-compatible API.

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
- [–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã](#–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ-–ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã)
- [–ù–∞—Å—Ç—Ä–æ–π–∫–∞](#–Ω–∞—Å—Ç—Ä–æ–π–∫–∞)
- [–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å](#—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)
- [–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ](#–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ)
- [CPU-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è](#cpu-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
- [–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å](#–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
- [Troubleshooting](#troubleshooting)

---

## –û–±–∑–æ—Ä

–°–∏—Å—Ç–µ–º–∞ VMS –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å LLM –¥–ª—è:

- üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Å–æ–±—ã—Ç–∏–π
- üîé –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ embeddings
- üìã –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤
- üó£Ô∏è –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∫–æ–º–∞–Ω–¥

### Graceful Fallback

–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–∞–∂–µ –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LLM:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ fallback-–ª–æ–≥–∏–∫—É
- –ë–∞–∑–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏ –æ—Ç—á—ë—Ç—ã –±–µ–∑ LLM
- –ù–∏–∫–∞–∫–∏—Ö –ø–∞–¥–µ–Ω–∏–π –∏–ª–∏ –∑–∞–≤–∏—Å–∞–Ω–∏–π

---

## –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã

### LM Studio

```env
LLM_PROVIDER=lmstudio
LLM_BASE_URL=http://localhost:1234/v1
```

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ LM Studio:**
1. –°–∫–∞—á–∞–π—Ç–µ —Å [lmstudio.ai](https://lmstudio.ai)
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä: `Server` ‚Üí `Start Server`
3. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–æ—Ä—Ç 1234 –¥–æ—Å—Ç—É–ø–µ–Ω

### Ollama

```env
LLM_PROVIDER=ollama
LLM_BASE_URL=http://localhost:11434/v1
```

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama:**
```bash
# Linux/macOS
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# –°–∫–∞—á–∞–π—Ç–µ —É—Å—Ç–∞–Ω–æ–≤—â–∏–∫ —Å ollama.ai

# –ó–∞–ø—É—Å–∫ –º–æ–¥–µ–ª–∏
ollama run llama2
```

---

## –ù–∞—Å—Ç—Ä–æ–π–∫–∞

### 1. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

–î–æ–±–∞–≤—å—Ç–µ –≤ `.env` —Ñ–∞–π–ª:

```env
# ==============================
# LLM Settings (LM Studio / Ollama)
# ==============================
LLM_ENABLED=true
LLM_PROVIDER=lmstudio
LLM_BASE_URL=http://localhost:1234/v1
LLM_MODEL=local-model
LLM_TIMEOUT=30
LLM_MAX_RETRIES=3
LLM_MIN_DELAY_SECONDS=5
LLM_MAX_CONCURRENT_CALLS=1
LLM_EMBEDDING_MODEL=nomic-embed-text
LLM_EMBEDDING_DIMENSION=768
LLM_HEALTH_CHECK_ENABLED=true
LLM_HEALTH_CHECK_TIMEOUT=5
LLM_CACHE_ENABLED=true
LLM_CACHE_TTL_SECONDS=3600
LLM_MAX_REQUEST_SIZE=10000
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
cd backend
pip install -r requirements.txt
```

### 3. –ú–∏–≥—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

```bash
# –î–ª—è PostgreSQL
alembic upgrade head

# –î–ª—è SQLite (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ)
# –ú–∏–≥—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞—Å—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è
```

### 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM Bridge

LLM Bridge –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ [`backend/app/main.py`](backend/app/main.py):

```python
from app.services import initialize_llm_bridge, shutdown_llm_bridge

@app.on_event("startup")
async def startup_event():
    await initialize_llm_bridge()

@app.on_event("shutdown")
async def shutdown_event():
    await shutdown_llm_bridge()
```

---

## –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å

### 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏–π —Å–æ–±—ã—Ç–∏–π

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–Ω—è—Ç–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Å–æ–±—ã—Ç–∏–π –∏–∑ JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```python
from app.services import get_llm_bridge

llm = get_llm_bridge()

event_data = {
    "event_type": "motion_detected",
    "camera_name": "Front Door",
    "timestamp": "2026-02-28T12:00:00",
    "confidence": 0.85,
    "metadata": {
        "motion_detected": True,
        "detected_objects": ["person"],
        "region": "entrance"
    }
}

description = await llm.generate_event_description(event_data)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: "–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥–≤–∏–∂–µ–Ω–∏–µ –Ω–∞ –∫–∞–º–µ—Ä–µ Front Door –≤ 12:00. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 85%."
```

**Fallback –±–µ–∑ LLM:**
```
"motion_detected –Ω–∞ –∫–∞–º–µ—Ä–µ 'Front Door' –≤ 2026-02-28T12:00:00"
```

### 2. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫

–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings –¥–ª—è —Å–æ–±—ã—Ç–∏–π –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```python
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding –¥–ª—è —Å–æ–±—ã—Ç–∏—è
event_text = "–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥–≤–∏–∂–µ–Ω–∏–µ –Ω–∞ –≤—Ö–æ–¥–µ"
embedding = await llm.generate_embedding(event_text)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
event.embedding = embedding
await db.commit()

# –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–±—ã—Ç–∏–π
from sqlalchemy import func
from pgvector.sqlalchemy import cosine_distance

query_embedding = await llm.generate_embedding("–ø–æ–∏—Å–∫ –¥–≤–∏–∂–µ–Ω–∏—è")

similar_events = await db.execute(
    select(Event)
    .order_by(cosine_distance(Event.embedding, query_embedding))
    .limit(10)
)
```

### 3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç—á—ë—Ç—ã

–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö —Å–≤–æ–¥–æ–∫ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–∞–º–µ—Ä.

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```python
from datetime import datetime, timedelta

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –∑–∞ –¥–µ–Ω—å
yesterday = datetime.now() - timedelta(days=1)
events = await get_events_by_date(yesterday)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞
report = await llm.generate_daily_report(events, yesterday)
```

**–ü—Ä–∏–º–µ—Ä –æ—Ç—á—ë—Ç–∞:**
```
–û—Ç—á—ë—Ç –∑–∞ 2026-02-27

–û–±–∑–æ—Ä –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:
–í—Å–µ–≥–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ 45 —Å–æ–±—ã—Ç–∏–π –Ω–∞ 5 –∫–∞–º–µ—Ä–∞—Ö.

–û—Å–Ω–æ–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è:
- –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥–≤–∏–∂–µ–Ω–∏–µ: 32 —Å–æ–±—ã—Ç–∏—è
- –û–±–Ω–∞—Ä—É–∂–µ–Ω —á–µ–ª–æ–≤–µ–∫: 12 —Å–æ–±—ã—Ç–∏–π
- –ö–∞–º–µ—Ä–∞ –æ—Ñ—Ñ–ª–∞–π–Ω: 1 —Å–æ–±—ã—Ç–∏–µ

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∫–∞–º–µ—Ä—É "Backyard" - –≤—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–æ—á—å—é
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞–º–µ—Ä—É "Garage" - –±—ã–ª–∞ –æ—Ñ–ª–∞–π–Ω 27 —Ñ–µ–≤—Ä–∞–ª—è
```

### 4. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∫–æ–º–∞–Ω–¥

–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–º–∞–Ω–¥—ã —Å–∏—Å—Ç–µ–º—ã.

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```python
# –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç Whisper
command_text = "–Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –Ω–∞ –∫–∞–º–µ—Ä–µ Front Door"

# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
result = await llm.interpret_voice_command(command_text)

# –†–µ–∑—É–ª—å—Ç–∞—Ç:
# {
#     "action": "start_recording",
#     "camera_name": "Front Door",
#     "parameters": {},
#     "confidence": 0.9
# }

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã
if result["action"] == "start_recording":
    await start_recording(result["camera_name"])
```

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∫–æ–º–∞–Ω–¥—ã:**
- `start_recording` - –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å
- `stop_recording` - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å
- `show_camera` - –ø–æ–∫–∞–∑–∞—Ç—å –∫–∞–º–µ—Ä—É
- `search_events` - –ø–æ–∏—Å–∫ —Å–æ–±—ã—Ç–∏–π
- `show_events` - –ø–æ–∫–∞–∑–∞—Ç—å —Å–æ–±—ã—Ç–∏—è
- `export_recording` - —ç–∫—Å–ø–æ—Ä—Ç –∑–∞–ø–∏—Å–∏
- `list_cameras` - —Å–ø–∏—Å–æ–∫ –∫–∞–º–µ—Ä

---

## CPU-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

–°–∏—Å—Ç–µ–º–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã –Ω–∞ CPU-only –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ö:

### Rate Limiting

–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5 —Å–µ–∫—É–Ω–¥):

```env
LLM_MIN_DELAY_SECONDS=5
```

### Concurrency Control

–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1):

```env
LLM_MAX_CONCURRENT_CALLS=1
```

### –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ

–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ LLM –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø—Ä–æ—Å–æ–≤:

```env
LLM_CACHE_ENABLED=true
LLM_CACHE_TTL_SECONDS=3600
```

### –¢–∞–π–º–∞—É—Ç—ã

–ó–∞—â–∏—Ç–∞ –æ—Ç –∑–∞–≤–∏—Å–∞–Ω–∏—è LLM:

```env
LLM_TIMEOUT=30
LLM_HEALTH_CHECK_TIMEOUT=5
```

### Retry Logic

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–≤—Ç–æ—Ä –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö:

```env
LLM_MAX_RETRIES=3
```

---

## –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∑–∞–ø—Ä–æ—Å–∞

```env
LLM_MAX_REQUEST_SIZE=10000
```

–ó–∞–ø—Ä–æ—Å—ã –ø—Ä–µ–≤—ã—à–∞—é—â–∏–µ –ª–∏–º–∏—Ç –æ—Ç–∫–ª–æ–Ω—è—é—Ç—Å—è —Å –æ—à–∏–±–∫–æ–π [`LLMRequestTooLargeError`](backend/app/services/llm_bridge.py:65).

### –ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤–∏–¥–µ–æ

–°–∏—Å—Ç–µ–º–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç:
- –í–∏–¥–µ–æ —Ñ–∞–π–ª—ã
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- –ê—É–¥–∏–æ—Ñ–∞–π–ª—ã (–∫—Ä–æ–º–µ —Ç–µ–∫—Å—Ç–∞ –æ—Ç Whisper)

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫

–í—Å–µ –æ—à–∏–±–∫–∏ LLM –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ [`backend/logs/ai.log`](backend/logs/ai.log):

```
2026-02-28 12:00:00 - ERROR - LLM request failed: timeout
2026-02-28 12:00:05 - WARNING - LLM unavailable, using fallback
```

### Health Check

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LLM –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ:

```env
LLM_HEALTH_CHECK_ENABLED=true
```

---

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –í API endpoints

```python
from app.services import get_llm_bridge
from fastapi import APIRouter, Depends

router = APIRouter()

@router.post("/events/{event_id}/describe")
async def describe_event(event_id: int):
    llm = get_llm_bridge()
    
    event = await get_event(event_id)
    event_data = event.to_dict()
    
    description = await llm.generate_event_description(event_data)
    
    event.description = description
    await db.commit()
    
    return {"description": description}
```

### –í workers

```python
from app.services import get_llm_bridge

async def process_event(event_data):
    llm = get_llm_bridge()
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è
    description = await llm.generate_event_description(event_data)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding
    embedding = await llm.generate_embedding(description)
    
    return {
        "description": description,
        "embedding": embedding
    }
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏

```python
from app.services import get_llm_bridge

llm = get_llm_bridge()

if llm.is_available:
    print("LLM –¥–æ—Å—Ç—É–ø–µ–Ω")
else:
    print(f"LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {llm.status}")
```

### –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏

```python
stats = llm.get_stats()

# {
#     "enabled": true,
#     "provider": "lmstudio",
#     "status": "enabled",
#     "model": "local-model",
#     "concurrent_requests": 0,
#     "cache_size": 15,
#     "health_checked": true
# }
```

---

## Troubleshooting

### LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω

**–ü—Ä–æ–±–ª–µ–º–∞:** `LLMStatus.UNAVAILABLE`

**–†–µ—à–µ–Ω–∏—è:**
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ LLM –∑–∞–ø—É—â–µ–Ω:
   ```bash
   # LM Studio
   curl http://localhost:1234/v1/models
   
   # Ollama
   curl http://localhost:11434/v1/models
   ```

2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ `.env`:
   ```env
   LLM_BASE_URL=http://localhost:1234/v1
   LLM_TIMEOUT=30
   ```

3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏:
   ```
   tail -f backend/logs/ai.log
   ```

### –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞

**–ü—Ä–æ–±–ª–µ–º–∞:** `LLMTimeoutError`

**–†–µ—à–µ–Ω–∏—è:**
1. –£–≤–µ–ª–∏—á—å—Ç–µ —Ç–∞–π–º–∞—É—Ç:
   ```env
   LLM_TIMEOUT=60
   ```

2. –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞:
   ```env
   LLM_MAX_REQUEST_SIZE=5000
   ```

3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞

**–ü—Ä–æ–±–ª–µ–º–∞:** –î–æ–ª–≥–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞

**–†–µ—à–µ–Ω–∏—è:**
1. –í–∫–ª—é—á–∏—Ç–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ:
   ```env
   LLM_CACHE_ENABLED=true
   LLM_CACHE_TTL_SECONDS=7200
   ```

2. –£–º–µ–Ω—å—à–∏—Ç–µ –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏:
   ```env
   LLM_MIN_DELAY_SECONDS=3
   ```

3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å

### –û—à–∏–±–∫–∏ pgvector

**–ü—Ä–æ–±–ª–µ–º–∞:** –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å embeddings

**–†–µ—à–µ–Ω–∏—è:**
1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ PostgreSQL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:
   ```bash
   psql --version
   ```

2. –í–∫–ª—é—á–∏—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ pgvector:
   ```sql
   CREATE EXTENSION IF NOT EXISTS vector;
   ```

3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–∏–≥—Ä–∞—Ü–∏—é:
   ```bash
   alembic current
   ```

### SQLite –≤–º–µ—Å—Ç–æ PostgreSQL

–°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å SQLite, –Ω–æ pgvector –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è:

```python
# Embeddings –±—É–¥—É—Ç —Ö—Ä–∞–Ω–∏—Ç—å—Å—è –∫–∞–∫ TEXT (JSON –º–∞—Å—Å–∏–≤)
# –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å
```

–î–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ PostgreSQL.

---

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:

```bash
cd backend
pytest tests/test_llm_integration.py -v
```

–ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞:

```bash
pytest tests/test_llm_integration.py::TestEventDescriptionGeneration::test_generate_description_success -v
```

---

## API Reference

### LLMBridge

–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM.

#### –ú–µ—Ç–æ–¥—ã

##### `async initialize() -> None`
–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –∏ health check.

##### `async shutdown() -> None`
–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤.

##### `async generate_event_description(event_data: Dict[str, Any]) -> str`
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è —Å–æ–±—ã—Ç–∏—è.

##### `async generate_embedding(text: str) -> Optional[List[float]]`
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding.

##### `async generate_daily_report(events: List[Dict[str, Any]], date: datetime) -> str`
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞.

##### `async interpret_voice_command(command: str) -> Dict[str, Any]`
–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã.

##### `get_stats() -> Dict[str, Any]`
–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–µ—Ä–≤–∏—Å–∞.

#### –°–≤–æ–π—Å—Ç–≤–∞

##### `status: LLMStatus`
–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å LLM.

##### `is_available: bool`
–î–æ—Å—Ç—É–ø–µ–Ω –ª–∏ LLM.

---

## –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã

### LLMProvider

```python
class LLMProvider(str, Enum):
    LMSTUDIO = "lmstudio"
    OLLAMA = "ollama"
```

### LLMStatus

```python
class LLMStatus(str, Enum):
    ENABLED = "enabled"
    DISABLED = "disabled"
    UNAVAILABLE = "unavailable"
    ERROR = "error"
```

---

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [LM Studio Documentation](https://lmstudio.ai/docs)
- [Ollama Documentation](https://ollama.ai/docs)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [pgvector Documentation](https://github.com/pgvector/pgvector)

---

## –õ–∏—Ü–µ–Ω–∑–∏—è

–ß–∞—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ VMS. –°–º. LICENSE —Ñ–∞–π–ª.
